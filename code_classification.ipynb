{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import random\n",
    "from sklearn import datasets\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data: Union[int, float, 'Value'], _children=())->None:\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        self._prev = set(_children)\n",
    "        self._backward = lambda : None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\"\n",
    "\n",
    "    def __add__(self, other: Union[int, float, 'Value'])->'Value': \n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other))\n",
    "        def _backward():\n",
    "            self.grad += 1 * out.grad #y=a+b, dy/da = 1\n",
    "            other.grad += 1 * out.grad  #dy/db = 1\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other: Union[int, float, 'Value'])->'Value': \n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other))\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad #y=a*b, dy/da = b\n",
    "            other.grad += self.data * out.grad #dy/db = a\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __neg__(self):\n",
    "        return self * -1 #-a = a*-1\n",
    "        \n",
    "    def __pow__(self, other: Union[int, float])->'Value':\n",
    "        out = Value(self.data ** other, (self,))\n",
    "        def _backward():\n",
    "            self.grad += other * self.data**(other-1) * out.grad #y = x^n, dy/dx=n*x**(n-1)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __truediv__(self, other: Union[int, float, 'Value'])->'Value':\n",
    "        return self * other**-1 #a/b = a *(b**-1)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other #b+a = a+b\n",
    "\n",
    "    def __rsub__(self, other): \n",
    "        return -self + other #b-a = -a+b\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other #b*a = a*b\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return self**-1 * other #b/a = (a**-1) * b\n",
    "\n",
    "    def __sub__(self, other: Union[int, float, 'Value'])->'Value':\n",
    "        return self + (-other) #a-b = a+(-b)\n",
    "\n",
    "    def relu(self)->'Value':\n",
    "        out = self.data if self.data>0 else 0\n",
    "        out = Value(out, (self,))\n",
    "        def _backward():\n",
    "            self.grad += (1 if self.data>0 else 0) * out.grad #y=x, dy=1 or #y=0, dy=n\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def exp(self)->'Value':\n",
    "        out = math.exp(self.data)\n",
    "        out = Value(out, (self,))\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad #y=e**x, #dy/dx=e**x\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def log(self)->'Value':\n",
    "        out = math.log(self.data)\n",
    "        out = Value(out, (self,))\n",
    "        def _backward():\n",
    "            self.grad += (1/self.data)* out.grad #y=ln(x), dy/dx=1/x\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        # topological order all of the children in the graph\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        # go one variable at a time and apply the chain rule to get its gradient\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    def __gt__(self, other)->bool:\n",
    "        return self.data > other.data #checks if a>b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_in: int, nonlin=True) -> None:\n",
    "        self.w = [\n",
    "            Value(random.uniform(-1, 1)) for _ in range(n_in)\n",
    "        ]  # initializes weights of the neuron\n",
    "        self.b = Value(0.0)  # initializes bias of the neuron\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "    def __call__(self, x:list)->'Value':\n",
    "        act = sum(\n",
    "            (wi * xi for wi, xi in zip(self.w, x)), self.b\n",
    "        )  # w1*x1+ w2*x2+ .... +wnxn + b\n",
    "        return act.relu() if self.nonlin else act\n",
    "\n",
    "    def parameters(self) -> list['Value']:\n",
    "        return self.w + [self.b]  # list of weights and biases of a neuron\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_in:int, n_out:int, **kwargs) -> None:\n",
    "        self.neurons = [\n",
    "            Neuron(n_in, **kwargs) for _ in range(n_out)\n",
    "        ]  # initializes neurons of a layer\n",
    "\n",
    "    def __call__(self, x:list) -> list['Value']:\n",
    "        out = [n(x) for n in self.neurons]  # outputs of all neurons in a layer\n",
    "        return out\n",
    "\n",
    "    def parameters(self) -> list['Value']:\n",
    "        params = [\n",
    "            p for n in self.neurons for p in n.parameters()\n",
    "        ]  # weights and biases of all neurons in a layer\n",
    "        return params\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Layer({self.neurons})\"\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, n_in: int, n_outs: list) -> None:  # MLP(4,[4, 3, 3])\n",
    "        sz = [n_in] + n_outs\n",
    "        self.layers = [\n",
    "            Layer(sz[i], sz[i + 1], nonlin=i != len(n_outs) - 1)\n",
    "            for i in range(len(n_outs))  # initializes layers of an MLP\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: list)->list['Value']:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  # fowards the output of a layer to the next layer\n",
    "        return x  # return the output of the last layer\n",
    "\n",
    "    def parameters(self)->list['Value']:\n",
    "        params = [p for layer in self.layers for p in layer.parameters()]\n",
    "        #parameters of all layers in an MLP\n",
    "        return params \n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0 #resets the gradients\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"MLP({self.layers})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data #features \n",
    "y = iris.target #label\n",
    "\n",
    "X = X.tolist()\n",
    "ys = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(logits:list)->list['Value']: #e^yi/e^y1+e^y2+...+e^yn for i in range(1, n+1)\n",
    "    denominator = sum((logit.exp() for logit in logits))\n",
    "    out = [logit.exp()/denominator for logit in logits]\n",
    "    return out\n",
    "\n",
    "def NLLLoss(sm_out: list, y:int)->'Value':\n",
    "    return -(sm_out[y]).log() #ln(sm_out)\n",
    "\n",
    "def loss_calc(y:int, logits:list)->'Value':\n",
    "    sm_out = Softmax(logits)\n",
    "    loss = NLLLoss(sm_out, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(4, [4,3,3]) #initialize the model \n",
    "epochs = 500 #no. of iteration\n",
    "lr=0.02 #learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Value(data=0.2716759461596869, grad=1)\n",
      "1 Value(data=0.27075585526365864, grad=1)\n",
      "2 Value(data=0.2698424353437808, grad=1)\n",
      "3 Value(data=0.26893563880332333, grad=1)\n",
      "4 Value(data=0.26803541871150527, grad=1)\n",
      "5 Value(data=0.2671417286701526, grad=1)\n",
      "6 Value(data=0.2662545227114834, grad=1)\n",
      "7 Value(data=0.265373755219985, grad=1)\n",
      "8 Value(data=0.2644993808727323, grad=1)\n",
      "9 Value(data=0.2636313545938764, grad=1)\n",
      "10 Value(data=0.26276963152004956, grad=1)\n",
      "11 Value(data=0.26191416697418274, grad=1)\n",
      "12 Value(data=0.2610649164458435, grad=1)\n",
      "13 Value(data=0.2602218355766194, grad=1)\n",
      "14 Value(data=0.2593850604802415, grad=1)\n",
      "15 Value(data=0.25855489735799614, grad=1)\n",
      "16 Value(data=0.25773082267145764, grad=1)\n",
      "17 Value(data=0.2569127685823161, grad=1)\n",
      "18 Value(data=0.2561006859176867, grad=1)\n",
      "19 Value(data=0.25529452682413895, grad=1)\n",
      "20 Value(data=0.2544942443499383, grad=1)\n",
      "21 Value(data=0.25369979228169354, grad=1)\n",
      "22 Value(data=0.25291112501866336, grad=1)\n",
      "23 Value(data=0.25212819747553794, grad=1)\n",
      "24 Value(data=0.2513509650071685, grad=1)\n",
      "25 Value(data=0.25057938335036667, grad=1)\n",
      "26 Value(data=0.2498134085789784, grad=1)\n",
      "27 Value(data=0.24905299706929745, grad=1)\n",
      "28 Value(data=0.2482981054735387, grad=1)\n",
      "29 Value(data=0.24754869069960206, grad=1)\n",
      "30 Value(data=0.2468047098957491, grad=1)\n",
      "31 Value(data=0.2460661204391237, grad=1)\n",
      "32 Value(data=0.24533287992727373, grad=1)\n",
      "33 Value(data=0.24460494617202808, grad=1)\n",
      "34 Value(data=0.24388227719521133, grad=1)\n",
      "35 Value(data=0.24316483122579916, grad=1)\n",
      "36 Value(data=0.24245256669819926, grad=1)\n",
      "37 Value(data=0.24174544225140993, grad=1)\n",
      "38 Value(data=0.24104350589053222, grad=1)\n",
      "39 Value(data=0.2403472899014509, grad=1)\n",
      "40 Value(data=0.23965610739051618, grad=1)\n",
      "41 Value(data=0.23896990701342607, grad=1)\n",
      "42 Value(data=0.23828864594215585, grad=1)\n",
      "43 Value(data=0.23761228219007727, grad=1)\n",
      "44 Value(data=0.2369407649416266, grad=1)\n",
      "45 Value(data=0.23627406250382627, grad=1)\n",
      "46 Value(data=0.23561213437653286, grad=1)\n",
      "47 Value(data=0.2349549404447269, grad=1)\n",
      "48 Value(data=0.23430244094724056, grad=1)\n",
      "49 Value(data=0.23365459645410913, grad=1)\n",
      "50 Value(data=0.23301136784869003, grad=1)\n",
      "51 Value(data=0.23237271631360204, grad=1)\n",
      "52 Value(data=0.23173859948529002, grad=1)\n",
      "53 Value(data=0.23110897866718239, grad=1)\n",
      "54 Value(data=0.23048381997719025, grad=1)\n",
      "55 Value(data=0.22986308572932193, grad=1)\n",
      "56 Value(data=0.2292467385026763, grad=1)\n",
      "57 Value(data=0.22863480539480247, grad=1)\n",
      "58 Value(data=0.2280273563053483, grad=1)\n",
      "59 Value(data=0.2274241906735037, grad=1)\n",
      "60 Value(data=0.22682531043148868, grad=1)\n",
      "61 Value(data=0.22623087957821778, grad=1)\n",
      "62 Value(data=0.22564062387935235, grad=1)\n",
      "63 Value(data=0.2250545042903899, grad=1)\n",
      "64 Value(data=0.22447248376308, grad=1)\n",
      "65 Value(data=0.22389452583117386, grad=1)\n",
      "66 Value(data=0.22332059449767627, grad=1)\n",
      "67 Value(data=0.2227508025920333, grad=1)\n",
      "68 Value(data=0.22218510059499721, grad=1)\n",
      "69 Value(data=0.22162333974571738, grad=1)\n",
      "70 Value(data=0.2210654780671754, grad=1)\n",
      "71 Value(data=0.2205114790191169, grad=1)\n",
      "72 Value(data=0.2199613069820435, grad=1)\n",
      "73 Value(data=0.21941492694645273, grad=1)\n",
      "74 Value(data=0.21887230444046973, grad=1)\n",
      "75 Value(data=0.2183334054801635, grad=1)\n",
      "76 Value(data=0.21779819652941865, grad=1)\n",
      "77 Value(data=0.21726664446698873, grad=1)\n",
      "78 Value(data=0.21673871655937618, grad=1)\n",
      "79 Value(data=0.2162143804384442, grad=1)\n",
      "80 Value(data=0.2156936040828815, grad=1)\n",
      "81 Value(data=0.21517635580280287, grad=1)\n",
      "82 Value(data=0.2146626042269065, grad=1)\n",
      "83 Value(data=0.21415231829171447, grad=1)\n",
      "84 Value(data=0.2136454690188558, grad=1)\n",
      "85 Value(data=0.2131421453770615, grad=1)\n",
      "86 Value(data=0.21264220808973525, grad=1)\n",
      "87 Value(data=0.21214562307778306, grad=1)\n",
      "88 Value(data=0.21165235944646102, grad=1)\n",
      "89 Value(data=0.21116238690696026, grad=1)\n",
      "90 Value(data=0.21067567557604852, grad=1)\n",
      "91 Value(data=0.21019219594048064, grad=1)\n",
      "92 Value(data=0.20971191883612644, grad=1)\n",
      "93 Value(data=0.20923481543106026, grad=1)\n",
      "94 Value(data=0.20876085721132964, grad=1)\n",
      "95 Value(data=0.2082900159688921, grad=1)\n",
      "96 Value(data=0.20782226379134014, grad=1)\n",
      "97 Value(data=0.20735757305309319, grad=1)\n",
      "98 Value(data=0.20689591640780897, grad=1)\n",
      "99 Value(data=0.20643726678179242, grad=1)\n",
      "100 Value(data=0.2059815973682374, grad=1)\n",
      "101 Value(data=0.20552888162214986, grad=1)\n",
      "102 Value(data=0.2050790932558403, grad=1)\n",
      "103 Value(data=0.20463220623488418, grad=1)\n",
      "104 Value(data=0.20418819477447092, grad=1)\n",
      "105 Value(data=0.20374703333607644, grad=1)\n",
      "106 Value(data=0.20330869662440132, grad=1)\n",
      "107 Value(data=0.2028731595845323, grad=1)\n",
      "108 Value(data=0.20244039739928907, grad=1)\n",
      "109 Value(data=0.20201038548672162, grad=1)\n",
      "110 Value(data=0.20158309949773937, grad=1)\n",
      "111 Value(data=0.20115851531384335, grad=1)\n",
      "112 Value(data=0.20073660904495091, grad=1)\n",
      "113 Value(data=0.20031735702729062, grad=1)\n",
      "114 Value(data=0.199900735821364, grad=1)\n",
      "115 Value(data=0.19948672220995678, grad=1)\n",
      "116 Value(data=0.19907529319619538, grad=1)\n",
      "117 Value(data=0.19866642600164114, grad=1)\n",
      "118 Value(data=0.19826009806441447, grad=1)\n",
      "119 Value(data=0.19785628703734826, grad=1)\n",
      "120 Value(data=0.19745497078616356, grad=1)\n",
      "121 Value(data=0.19705612738766515, grad=1)\n",
      "122 Value(data=0.19665973512795376, grad=1)\n",
      "123 Value(data=0.19626577188389713, grad=1)\n",
      "124 Value(data=0.1958742102811638, grad=1)\n",
      "125 Value(data=0.19548503597452083, grad=1)\n",
      "126 Value(data=0.19509822807039343, grad=1)\n",
      "127 Value(data=0.19471376587688238, grad=1)\n",
      "128 Value(data=0.1943316289008694, grad=1)\n",
      "129 Value(data=0.19395179684621258, grad=1)\n",
      "130 Value(data=0.1935742496120519, grad=1)\n",
      "131 Value(data=0.19319896729113537, grad=1)\n",
      "132 Value(data=0.1928259298027305, grad=1)\n",
      "133 Value(data=0.1924551122630566, grad=1)\n",
      "134 Value(data=0.19208650114709833, grad=1)\n",
      "135 Value(data=0.19172007730470916, grad=1)\n",
      "136 Value(data=0.19135582177154276, grad=1)\n",
      "137 Value(data=0.19099371576694174, grad=1)\n",
      "138 Value(data=0.190633740692261, grad=1)\n",
      "139 Value(data=0.19027587812924332, grad=1)\n",
      "140 Value(data=0.18992010983840588, grad=1)\n",
      "141 Value(data=0.18956641775743452, grad=1)\n",
      "142 Value(data=0.18921478399958494, grad=1)\n",
      "143 Value(data=0.18886519085209189, grad=1)\n",
      "144 Value(data=0.1885176207745843, grad=1)\n",
      "145 Value(data=0.18817205639750953, grad=1)\n",
      "146 Value(data=0.1878284805205654, grad=1)\n",
      "147 Value(data=0.18748687611114018, grad=1)\n",
      "148 Value(data=0.18714722630275918, grad=1)\n",
      "149 Value(data=0.18680951439354285, grad=1)\n",
      "150 Value(data=0.18647372384467045, grad=1)\n",
      "151 Value(data=0.1861398382788544, grad=1)\n",
      "152 Value(data=0.18580784147882196, grad=1)\n",
      "153 Value(data=0.1854777173858072, grad=1)\n",
      "154 Value(data=0.18514946926565282, grad=1)\n",
      "155 Value(data=0.18482341546841452, grad=1)\n",
      "156 Value(data=0.18449919139571963, grad=1)\n",
      "157 Value(data=0.1841767779333441, grad=1)\n",
      "158 Value(data=0.18385615899301122, grad=1)\n",
      "159 Value(data=0.18353731901270867, grad=1)\n",
      "160 Value(data=0.18322024266520417, grad=1)\n",
      "161 Value(data=0.18290491481784327, grad=1)\n",
      "162 Value(data=0.18259132052161275, grad=1)\n",
      "163 Value(data=0.1822794450043011, grad=1)\n",
      "164 Value(data=0.18196927366472795, grad=1)\n",
      "165 Value(data=0.18166079206762503, grad=1)\n",
      "166 Value(data=0.1813539859390427, grad=1)\n",
      "167 Value(data=0.18104884116220687, grad=1)\n",
      "168 Value(data=0.1807453437737634, grad=1)\n",
      "169 Value(data=0.1804434799603576, grad=1)\n",
      "170 Value(data=0.18014323605550042, grad=1)\n",
      "171 Value(data=0.17984459853668708, grad=1)\n",
      "172 Value(data=0.1795475540009391, grad=1)\n",
      "173 Value(data=0.17925208524471403, grad=1)\n",
      "174 Value(data=0.1789581831886895, grad=1)\n",
      "175 Value(data=0.1786658337796482, grad=1)\n",
      "176 Value(data=0.17837513607066446, grad=1)\n",
      "177 Value(data=0.17808606838284427, grad=1)\n",
      "178 Value(data=0.1777985213138382, grad=1)\n",
      "179 Value(data=0.17751247973446072, grad=1)\n",
      "180 Value(data=0.17722793062958156, grad=1)\n",
      "181 Value(data=0.1769448613963948, grad=1)\n",
      "182 Value(data=0.1766632596265104, grad=1)\n",
      "183 Value(data=0.1763831130732934, grad=1)\n",
      "184 Value(data=0.17610445510769998, grad=1)\n",
      "185 Value(data=0.17582737571299242, grad=1)\n",
      "186 Value(data=0.17555171477014278, grad=1)\n",
      "187 Value(data=0.17527746220615276, grad=1)\n",
      "188 Value(data=0.17500460607168405, grad=1)\n",
      "189 Value(data=0.17473313467684223, grad=1)\n",
      "190 Value(data=0.17446309839838275, grad=1)\n",
      "191 Value(data=0.17419448922538128, grad=1)\n",
      "192 Value(data=0.1739272935259267, grad=1)\n",
      "193 Value(data=0.1736613169341144, grad=1)\n",
      "194 Value(data=0.1733967448304831, grad=1)\n",
      "195 Value(data=0.1731334996581273, grad=1)\n",
      "196 Value(data=0.17287155795225512, grad=1)\n",
      "197 Value(data=0.1726109116840339, grad=1)\n",
      "198 Value(data=0.17235155009627853, grad=1)\n",
      "199 Value(data=0.17209346271941536, grad=1)\n",
      "200 Value(data=0.17183663923849024, grad=1)\n",
      "201 Value(data=0.17158106947119653, grad=1)\n",
      "202 Value(data=0.1713267433605439, grad=1)\n",
      "203 Value(data=0.17107365097011118, grad=1)\n",
      "204 Value(data=0.17082178247993998, grad=1)\n",
      "205 Value(data=0.17057112818287173, grad=1)\n",
      "206 Value(data=0.1703216784812207, grad=1)\n",
      "207 Value(data=0.17007342388374638, grad=1)\n",
      "208 Value(data=0.1698263550028899, grad=1)\n",
      "209 Value(data=0.16958046255223666, grad=1)\n",
      "210 Value(data=0.16933573734418572, grad=1)\n",
      "211 Value(data=0.16909217028779383, grad=1)\n",
      "212 Value(data=0.16884975238677905, grad=1)\n",
      "213 Value(data=0.16860847473766316, grad=1)\n",
      "214 Value(data=0.16836832852803643, grad=1)\n",
      "215 Value(data=0.1681293050349317, grad=1)\n",
      "216 Value(data=0.1678913956232963, grad=1)\n",
      "217 Value(data=0.16765459174454755, grad=1)\n",
      "218 Value(data=0.16741888493520754, grad=1)\n",
      "219 Value(data=0.16718426657857732, grad=1)\n",
      "220 Value(data=0.1669507276456434, grad=1)\n",
      "221 Value(data=0.16671826090482167, grad=1)\n",
      "222 Value(data=0.1664868582210036, grad=1)\n",
      "223 Value(data=0.16625651096077107, grad=1)\n",
      "224 Value(data=0.16602721034010237, grad=1)\n",
      "225 Value(data=0.16579894987653085, grad=1)\n",
      "226 Value(data=0.1655717217451589, grad=1)\n",
      "227 Value(data=0.1653455181962444, grad=1)\n",
      "228 Value(data=0.1651203315542171, grad=1)\n",
      "229 Value(data=0.16489615421679052, grad=1)\n",
      "230 Value(data=0.16467297865408967, grad=1)\n",
      "231 Value(data=0.16445079740780677, grad=1)\n",
      "232 Value(data=0.1642296030903712, grad=1)\n",
      "233 Value(data=0.16400938838413906, grad=1)\n",
      "234 Value(data=0.16379014604059863, grad=1)\n",
      "235 Value(data=0.16357186887959027, grad=1)\n",
      "236 Value(data=0.1633545497885422, grad=1)\n",
      "237 Value(data=0.1631381817217174, grad=1)\n",
      "238 Value(data=0.16292275769947537, grad=1)\n",
      "239 Value(data=0.16270827080754535, grad=1)\n",
      "240 Value(data=0.16249471419631012, grad=1)\n",
      "241 Value(data=0.16228208108010164, grad=1)\n",
      "242 Value(data=0.1620703647365071, grad=1)\n",
      "243 Value(data=0.1618595585056857, grad=1)\n",
      "244 Value(data=0.16164965578969262, grad=1)\n",
      "245 Value(data=0.1614406500518157, grad=1)\n",
      "246 Value(data=0.1612325348159188, grad=1)\n",
      "247 Value(data=0.16102530366579423, grad=1)\n",
      "248 Value(data=0.160818950244525, grad=1)\n",
      "249 Value(data=0.16061346825385298, grad=1)\n",
      "250 Value(data=0.16040885145355774, grad=1)\n",
      "251 Value(data=0.16020509366084126, grad=1)\n",
      "252 Value(data=0.16000218874972003, grad=1)\n",
      "253 Value(data=0.159800130650427, grad=1)\n",
      "254 Value(data=0.15959891334881796, grad=1)\n",
      "255 Value(data=0.15939853088578676, grad=1)\n",
      "256 Value(data=0.15919897735668698, grad=1)\n",
      "257 Value(data=0.15900024691076062, grad=1)\n",
      "258 Value(data=0.15880233375057326, grad=1)\n",
      "259 Value(data=0.15860523213145628, grad=1)\n",
      "260 Value(data=0.1584089363609548, grad=1)\n",
      "261 Value(data=0.15821344079828348, grad=1)\n",
      "262 Value(data=0.15801873985378637, grad=1)\n",
      "263 Value(data=0.1578248279884054, grad=1)\n",
      "264 Value(data=0.15763169971315283, grad=1)\n",
      "265 Value(data=0.15743934958859135, grad=1)\n",
      "266 Value(data=0.1572477722028617, grad=1)\n",
      "267 Value(data=0.157056960818482, grad=1)\n",
      "268 Value(data=0.156866911587899, grad=1)\n",
      "269 Value(data=0.1566776192643644, grad=1)\n",
      "270 Value(data=0.15648907864821196, grad=1)\n",
      "271 Value(data=0.15630128458632647, grad=1)\n",
      "272 Value(data=0.15611423197166605, grad=1)\n",
      "273 Value(data=0.15592791574278306, grad=1)\n",
      "274 Value(data=0.1557423308833562, grad=1)\n",
      "275 Value(data=0.15555747242172455, grad=1)\n",
      "276 Value(data=0.15537333543042925, grad=1)\n",
      "277 Value(data=0.15518991502575877, grad=1)\n",
      "278 Value(data=0.1550072063672994, grad=1)\n",
      "279 Value(data=0.15482520465749186, grad=1)\n",
      "280 Value(data=0.15464390514119106, grad=1)\n",
      "281 Value(data=0.15446331448954007, grad=1)\n",
      "282 Value(data=0.15428353903467953, grad=1)\n",
      "283 Value(data=0.1541044539912191, grad=1)\n",
      "284 Value(data=0.1539260531573004, grad=1)\n",
      "285 Value(data=0.1537483316443136, grad=1)\n",
      "286 Value(data=0.15357128480867474, grad=1)\n",
      "287 Value(data=0.15339490808475745, grad=1)\n",
      "288 Value(data=0.15321922682151165, grad=1)\n",
      "289 Value(data=0.15304424893136995, grad=1)\n",
      "290 Value(data=0.1528699286494523, grad=1)\n",
      "291 Value(data=0.15269626117487167, grad=1)\n",
      "292 Value(data=0.15252324203056417, grad=1)\n",
      "293 Value(data=0.1523508668329193, grad=1)\n",
      "294 Value(data=0.15217913125381247, grad=1)\n",
      "295 Value(data=0.1520080310138837, grad=1)\n",
      "296 Value(data=0.15183756188016606, grad=1)\n",
      "297 Value(data=0.15166771966469747, grad=1)\n",
      "298 Value(data=0.1514985002232722, grad=1)\n",
      "299 Value(data=0.15132989945432038, grad=1)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    logits = list(map(model, X)) #forward pass\n",
    "    loss = sum(list(map(loss_calc, ys, logits)))/len(ys) #NLLLoss calculation\n",
    "    loss.backward() #backward pass, gradient calculation\n",
    "    for p in model.parameters():\n",
    "        p.data -= p.grad * lr #update weights and biases\n",
    "    model.zero_grad() #reseting gradients\n",
    "    print(epoch, loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "out = [logit.index(max(logit)) for logit in logits]\n",
    "correct =0\n",
    "for a, b in zip(ys, out):\n",
    "    if a == b:\n",
    "        correct +=1\n",
    "correct/len(ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_new_vers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
